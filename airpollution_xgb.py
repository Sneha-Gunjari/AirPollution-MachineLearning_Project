# -*- coding: utf-8 -*-
"""AirPollution_xgb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xHKnwCp_kFuRvLnjQba9WGVw7YGeQ17H
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import xgboost as xgb

# Load the preprocessed data
train_df = pd.read_csv('/content/drive/MyDrive/Ml project/train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/Ml project/test.csv')
submission_df = pd.read_csv('/content/drive/MyDrive/Ml project/sample_submission.csv')

# Define the features to be used in the model
features = ['deg_C', 'relative_humidity', 'absolute_humidity', 'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5']

# Train a separate model for each target variable
for target_col in ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']:

    # Split the data into training and validation sets
    train_data, valid_data, train_target, valid_target = train_test_split(train_df[features], train_df[target_col], test_size=0.2, random_state=42)

    # Define the XGBoost model and train it
    model = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.05, random_state=42)
    model.fit(train_data, train_target, early_stopping_rounds=10, eval_set=[(valid_data, valid_target)])

    # Evaluate the model on the validation set
    valid_predictions = model.predict(valid_data)
    mse = mean_squared_error(valid_target, valid_predictions)
    print(f'{target_col} validation set MSE: {mse:.4f}')

    # Make predictions on the testing set and generate a submission file for the current target variable
    test_predictions = model.predict(test_df[features])
    submission_df[target_col] = test_predictions
    submission_df.to_csv(f'submission_{target_col}.csv', index=False)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import xgboost as xgb

# Load the preprocessed data
train_df = pd.read_csv('/content/drive/MyDrive/Ml project/train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/Ml project/test.csv')
submission_df = pd.read_csv('/content/drive/MyDrive/Ml project/sample_submission.csv')

# Define the features to be used in the model
features = ['deg_C', 'relative_humidity', 'absolute_humidity', 'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5']

# Initialize a variable to store the overall RMSLE
overall_rmsle = 0

# Train a separate model for each target variable
for target_col in ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']:

    # Split the data into training and validation sets
    train_data, valid_data, train_target, valid_target = train_test_split(train_df[features], train_df[target_col], test_size=0.2, random_state=42)

    # Define the XGBoost model and train it
    model = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.05, random_state=42)
    model.fit(train_data, train_target, early_stopping_rounds=10, eval_set=[(valid_data, valid_target)])

    # Evaluate the model on the validation set
    valid_predictions = model.predict(valid_data)
    mse = mean_squared_error(valid_target, valid_predictions)
    rmsle = np.sqrt(mse)
    print(f'{target_col} validation set RMSLE: {rmsle:.4f}')

    # Add the RMSLE for the current target variable to the overall RMSLE
    overall_rmsle += rmsle

    # Make predictions on the testing set and generate a submission file for the current target variable
    test_predictions = model.predict(test_df[features])
    submission_df[target_col] = test_predictions
    submission_df.to_csv(f'submission_{target_col}.csv', index=False)

# Calculate the overall RMSLE and print it
overall_rmsle /= 3
print(f'Overall RMSLE: {overall_rmsle:.4f}')

# import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_squared_log_error

# Load the dataset
train_df = pd.read_csv('/content/drive/MyDrive/Ml project/train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/Ml project/test.csv')

# Define the features and target variables
features = ['deg_C', 'relative_humidity', 'absolute_humidity','sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5']
targets = ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']

# Split the training data into features and targets
X_train = train_df[features]
y_train = train_df[targets]

# Define the XGBoost model and its hyperparameters
xgb_model = xgb.XGBRegressor(objective='reg:squaredlogerror',
                             learning_rate=0.1,
                             max_depth=6,
                             n_estimators=1000,
                             subsample=0.8,
                             colsample_bytree=0.8,
                             random_state=42)

# Fit the model on the training data
xgb_model.fit(X_train, y_train, verbose=False)

# Make predictions on the test data
X_test = test_df[features]
y_pred = xgb_model.predict(X_test)

# Create a submission dataframe
submission_df = pd.DataFrame({'date_time': test_df['date_time']})
#submission_df = pd.concat([submission_df, pd.DataFrame(y_pred,vcolumns=targets)], axis=1)

# Save the submission dataframe to a CSV file
submission_df.to_csv('submission.csv', index=False)

# Calculate the mean column-wise root mean squared logarithmic error(RMSLE) for each target variable on the validation set
X_val = X_train.sample(frac=0.2, random_state=42)
y_val = y_train.loc[X_val.index]
y_pred_val = xgb_model.predict(X_val)
rmsle_co = np.sqrt(mean_squared_log_error(y_val['target_carbon_monoxide'],y_pred_val[:, 0]))
rmsle_ben = np.sqrt(mean_squared_log_error(y_val['target_benzene'],y_pred_val[:, 1]))
rmsle_no = np.sqrt(mean_squared_log_error(y_val['target_nitrogen_oxides'],y_pred_val[:, 2]))
overall = rmsle_co + rmsle_ben + rmsle_no
print('RMSLE - Carbon Monoxide:', rmsle_co)
print('RMSLE - Benzene:', rmsle_ben)
print('RMSLE - Nitrogen Oxides:', rmsle_no)
print('Overall: ',overall/3)